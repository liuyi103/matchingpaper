%File: formatting-instruction.tex
\documentclass[letterpaper]{article}
\usepackage{ijcai15}
\usepackage{times}
\usepackage{url}
\usepackage{helvet}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{balance}
\usepackage{amsmath}
\usepackage{xcolor}
\newtheorem{theorem}{Theorem}%[section]
\newtheorem{proposition}{Proposition}
\newenvironment{proof}{{Proof:}}{\hfill\rule{2mm}{2mm}}
\newenvironment{mechanism}{Mechanism}{\hfill\rule{2mm}{2mm}}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{property}{Property}

\title {OptOrder: optimum serial dictatorship in stochastic matching}
\author {Someone}
 \begin{document}
% The file aaai.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

\maketitle
\begin{abstract}
This paper studies a simplified version of the stochastic matching proposed in \cite{chen2009approximating}.
Previous study want to find the optimal policy for a matching system to maximize the cardinality of a matching. 
In that setting, an agent may reject the assigned candidate (with a certain probability) and stay in the market or leave.
Finding the optimum policy to match meets great difficulties mainly from two aspects.
First, there is no evidence that the optimal policy can be expressed in polynomial space.
Second, collecting the acceptance ratio of each pair usually incurs considerable costs.

To express a policy efficiently and solve the optimum solution efficiently, we choose serial dictatorship and consider the case where the acceptance ratios are identical for each pair.
This paper aims to give an algorithm with a graph and the acceptance ratio as input and outputs a optimum order for serial dictatorship.
We first describe a straightforward integer linear programming with $O(|E|^4)$ entries.
Then, we reduce the number of entries to $O(|E|^2)$ by an important observation.
Finally, in the experimental part, we compare methods to solve even larger graphs.

\end{abstract}

\section{Introduction}

Motivated by applications like kidney exchange and online dating, \cite{chen2009approximating} defines stochastic matching.
The goal to maximize the cardinality of a stochastic matching.
The problem can be modeled in a graph.
Any edge has a probability to be fake. (In our work, we assume that these probabilities are identical.)
When a fake edge is probed to match, it rejects the prob and the edge is removed from the graph.
Otherwise, it accepts the prob and both ends of the edge are removed from the graph.
They show a greedy algorithm with 0.25 approximation compared to the optimal algorithm.
The approximation ratio was improved by \cite{adamczyk2011improved,costello2012stochastic}.
When compared to the offline optimal, this problem is closely related to the randomized greedy matching problem.
\cite{poloczek2012randomized,aronson1995randomized} show a greedy algorithm that can match more than one half agents and
\cite{goel2012matching} improve the lower bound significantly.


The current setting faces two main drawbacks to prevent it from practical use.

First, to know the exact probability of a prob being accepted is difficult.
Typically, in order to know the exact probabilities, the market needs to collect many data and conduct careful analyses on historical data.
It is worthy in important markets like kidney exchange market~\cite{dickerson2013failure,dickerson2015futurematch}.
However, in many less important market, collecting acceptance ratios is quite costly and unworthy.
Similar to online dating problem, let us consider a friend recommendation problem.
Someone (called Alice) has many friends, $x$ of them are single boys and $y$ are single girls.
Alice wants to introduce boys to girls for marriage.
She wants to maximize the number of matched couples.
Every boy or girl has some requirements that must be satisfied.
However, even though a boy and a girl satisfy each other's requirements, they may still not be willing to match.
In this case, it is hard and costly for Alice to survey the acceptance ratio of each pair.
Similar problem also appear in other applications like roommate problem~\cite{roth1982incentive}, but never serious considered as far as we know.

Second, as mentioned above, most study focus on giving worst case guarantees, compared both to the optimal solution and the offline optimum. 
The main difficulty preventing people to desire the optimum solution is that the optimal solution maybe not able to be expressed in polynomial space.
To solve the stochastic matching problem in practical, there is no evidence that the existing algorithms can work well enough.

In this paper, a simplified setting of stochastic matching is considered, which can still be utilized to solve many real life applications.
We assume that all the edges have the same acceptance ratio.
This assumption avoid the difficulty in surveying the acceptance probabilities and provides an essential condition for our algorithm.
As for the expressiveness of the solution, we improve it by serial dictatorship.
Although, serial dictatorship may reduce the expected number of matched agents, our experimental results demonstrate that the influence is not big.
With the solution, anyone can conduct the matching without any further help of a computer. 
One only needs $O(1)$ computation in average for each prob.
We are going to release our work as an open source tool. 
With the help of this tool, anyone is able make precise decisions for stochastic matching problems around themselves. 

The following part of this paper is organized as follows. Section 2 defines the serial dictatorship and show some fundamental good properties of it. Section 3 shows the construction of the integer linear programming step by step and prove its correctness. Section 4 explores methods to expand our algorithm to larger graphs. Section 5 shows our experimental results. Section 6 concludes this paper.


\section{The settings}

In this section, we will describe our model and the serial dictatorship. After that, some desired properties of serial dictatorship are demonstrated.

\subsection{The model}

Our problem is modeled in an undirected graph $G=(V,E)$, $V=\{v_1,v_2,\ldots,v_n\}$ denotes the set of agents. $e_{ij}\in E$ denotes an edge between $v_i$ and $v_j$.
For any edge $e_{ij}\in E$, it has two states, \textit{exist} or \textit{fake}.
The probability of ``exist'' is a constant $p$.
The goal of the matching is to maximize cardinality. Each time, the system prob a pair of agents $v_i$ and $v_j$ with an edge $e_{ij}$ connecting them. 
\begin{itemize}
	\item If $e_{ij}$ exists, then $v_i$ and $v_j$ agree to match with each other, both of the two agents and the edges attached to them are removed from the graph. 
	The number of matched agents increases by 2.
	\item If $e_{ij}$ is fake, $v_i$ and $v_j$ refuses to match. The system removes $e_{ij}$ from $E$.
\end{itemize}


\subsection{ESD algorithm}

To maximize the number of matched agents, we apply \textit{edge serial dictatorship algorithm} (ESD).
The outline is described In Algorithm \ref{alg:esd}.

\begin{algorithm}
	\caption{ESD algorithm}
	\label{alg:esd}
	\begin{algorithmic}[1]
		\Require
		A sorted array of $E$, denoted by $S=s_1,s_2,\ldots,s_m$ and the set of vertices $V$.
		\Ensure A set of disjoint edges $A$, such that each two agents connected by an edge in $A$ agree to match. 
		\State $A=\emptyset$
		\For $i=1,2,\ldots,m$
		\State Let $v_x$ and $v_y$ be the two agents connected by $s_i$
		\If $v_x\in V$ and $v_y\in V$
		\State Prob $v_x$ and $v_y$ whether they agree to match with each other.
		\If Both $v_x$ and $v_y$ accept to match
		\State Put $s_i$ into $A$
		\State Remove $v_x$ and $v_y$ from $V$
		\EndIf
		\EndIf
		\EndFor
		\State Outputs $A$ as the set of matched edges.
	\end{algorithmic}
\end{algorithm}

Algorithm \ref{alg:esd} is a typical serial dictator algorithm. 
The system just picks edges one by one in some order (denoted by $S$) and try to match the current edge if both ends of the edge are still in the graph. 
Our goal is to maximize the expected size of the output set $A$ among all $S$.

\subsection{Desired properties}

We restrict our focus on the serial dictatorship for many reasons.

\textbf{Usability}. The solution of ESP has a size of $O(|E|)$, which equals to the size of input. The executor of the matching only needs to use O(1) computation for each prob. These two properties make the solution perfect to be used as handouts. In other words, the order can be generated by a computer and any people can execute the matching without a computer.

\textbf{Deterministic}. A great advantage of ESD is that it outputs a deterministic solution. One can count the expected number of matched agents easily. 
Many previous algorithms lack this property.
In our setting, given the serial $S$, the expected number of matched agents $c(S)$ can be counted by the following equation.
\begin{equation}\label{obj}
c(S)=2*\sum_{i=1}^m p(1-p)^{\sum_{j=1}^{i-1}\delta(s_j,s_i)}
\end{equation}

In equation \ref{obj}, $\delta(s_i,s_j)$ is an indicator of whether $s_j$ appears before $s_i$ and they have a common vertex. In other words, $\delta(s_j,s_i)=1$ only when $s_j$ is probed before $s_i$ and they have a common vertex, otherwise  $\delta(s_j,s_i)=0$. 
In the integer linear programming, we will use variables $\delta_{ij}$, which holds the same meaning as $\delta(s_i,s_j)$ here.

\section{Optimizing the serial}

Algorithm \ref{alg:esd} has given a framework of serial dictatorship. 
The problem is how to find the serial  $S$ that maximizing the expected cardinality of the matching.
In this section, we will introduce the integer linear program (ILP) we used to find the optimum $S$ step by step.

\subsection{Overview of the algorithm}

The objective function of our ILP is a representation of Equation \ref{obj}.
As for the constraints, if we faithfully write the constrains according to definition of serial dictatorship and the objective function, we need $O(|E|^4)$ variables in the ILP, which is insufferable. We are not going to discuss in details for this idea.

To reduce the number of variables, we introduce a novel method.
We first relax the solution space to obtain a relaxed-form ILP.
Then, we show that the solution of the relaxed-form ILP can be mapped to the optimal serial $S$.

The relaxed-form ILP is based on the following observation.
Given the optimal serial $S$, there is a determined order between any two edge.
For example, for $e_{ij}, e_{ik}\in E$, given $S$, we know that $e_{ij}$ is always probed before $e_{ik}$ or $e_{ik}$ is always before $e_{ij}$.
Now, we are ready to relax the solution space.
Rather than a total order, we only assume that there is a determined order between any two edges with a common vertex.
We do not have any other constraints on the solution space.
Then, we will introduce a method that maps the optimal solution of the relaxed-form ILP to the optimal serial $S$ in ESD algorithm.
The relaxed-form ILP only has $O(|E|^2)$ variables and $O(|E|^2)$ entries in total.
So, it improves the performance significantly.

\subsection{Variable Definition}

Three types of variables are used in our ILP\footnote{From here on, all the ``ILP'' refers to the relaxed-form ILP.}.
For a better presentation of our ILP, we give an alias for each element in $E$.
We number all the edges in $E$ as $e^1,e^2,\ldots,e^m$.
This notation is not conflict with the previous definition.
An edge $e^i$ may denote the same meaning as $e_{jk}$.
Now, we are ready to define the variables in our setting.
\begin{itemize}
	\item $\delta_{ij}(i,j\in\{1,2,\ldots,m\})$ denotes an indicator of $e_i$ is probed before $e_j$ and they have a common vertex (just as mentioned before). If both conditions are satisfied $\delta_{ij}=1$, otherwise $\delta_{ij}=0$. The value of $\delta_{ij}$ is selected from $\{0,1\}$.
	\item $o_i(i\in\{1,2,\ldots,m\})$ denotes the number of edges that are probed before $e_i$ and have a common vertex as $e_i$. By definition, we have $o_i=\sum_{j=1}^{m}\delta_{ji}$. This equation is also used as a constraint in the ILP. The value of $o_i$ is selected from nonnegative integers
	\item $l_{ij}(i,j\in\{1,2,\ldots,m\})$ denotes an indicator for whether $o_i$ is greater than or equal to $j$. This variable is used to express the objective function of ILP. Its value is selected from $\{0,1\}$.
\end{itemize}

\subsection{Objective function}

The objective of the ILP is to maximize to total number of cardinality, which has been shown in Equation \ref{obj}.
To express it in the ILP fashion, we write it as follows. The index ``2'' is omitted, thus the objective function becomes the expected number of matched edges.

\begin{eqnarray}
	obj&=&\sum_{i=1}^{m}p*(1-p)^{o_i}\\
	&= & p*\sum_{i=1}^{m} ((1-p)^{o_i}-(1-p)^{o_{i}-1}+(1-p)^{o_{i}-1}-\nonumber\\
	&&(1-p)^{o_{i}-2}+\ldots-(1-p)+(1-p)-1+1)\\
	&=& mp+p*\sum_{i=1}^{m}\sum_{j=1}^{o_i}((1-p)^j-(1-p)^{j-1})\\
	&=& mp+p*\sum_{i=1}^{m}\sum_{j=1}^{m}((1-p)^j-(1-p)^{j-1})l_{ij}\label{fobj}
\end{eqnarray}

In equation \ref{fobj}, the objective function becomes a linear function, such that it can be used in the ILP.
The current problem is how to make $l_{ij}$ an indicator for $o_i\geq j$.

As stated before, the solution of the ILP only make sense when the objective function $obj$ has been maximized.
So, we only need to add the following constraint to restrict $l_{ij}$.
\begin{equation}
o_i\leq j-1+l_{ij}*|E|\label{lcon}
\end{equation}

In our ILP, $l_{ij}$ only appears in the constraint above and the objective function.

\begin{lemma}\label{lmm}
	When $obj$ has been maximized, $o_i\geq j$ if and only if $l_{ij}=1$.
\end{lemma}
\begin{proof}
	To prove this lemma, we only need to show that the following two cases are impossible when $obj$ is maximized.
	\begin{itemize}
		\item $o_i<j$ and $l_{ij}=1$.
		\item $o_i>j$ and $l_{ij}=0$.
	\end{itemize}
	The second case is obviously impossible by Equation \ref{lcon}.
	
	If the first case is satisfied and $obj$ is maximized, set $l_{ij}$ to be 0 will increase the $obj$ and all the constraints are still satisfied. A contradiction.
\end{proof}

\subsection{The ILP}
Now we are ready to conclude the ILP we used to solve the optimal serial as follows.

\begin{eqnarray}
\text{Maximize:}&& mp+p*\sum_{i=1}^{m}\sum_{j=1}^{m}((1-p)^j-(1-p)^{j-1})l_{ij}\nonumber\\
\text{Subject to:}&& 1.~\delta_{ij}+\delta{ji}=1, \forall e_i,e_j\in E, e_i\cap e_j\neq \emptyset \label{con1}\\
&& 2.~o_i\leq j-1+l_{ij}*|E|, \forall i,j\in \{1,2,\ldots,m\}\nonumber\\
&& 3.~o_i=\sum_{j=1}^{m}\delta_{ji}, \forall i=1,2,\ldots,m \nonumber
\end{eqnarray}

In equation \ref{con1}, $e_i\cap e_j\neq \emptyset$ denotes that $e_i$ and $e_j$ have a vertex in common. 

\subsection{Mapping to ESD}
We note that when the objective function is not maximized, the values of variables correspond to nothing useful for serial dictatorship.
However, when the objective function, things become different.
Now, we are going to show how to map the solution of the ILP to the optimal sequence $S$ for ESD.
The method is as follows.

\textbf{Mapping process: }First, we define a function $o$ satisfying $o(e_i)=o_i^*$. 
Note that we reuse the $o$ for the same meaning.
$o_i^*$ denotes the value of $o_i$ when the objective function in the ILP has been maximized.
Then, we sort the $E$ to be a sequence $S^*=s_1^*,s_2^*,\ldots,s_m^*$, satisfying $\forall i,j\in\{1,2,\ldots,m\}$, $o(s_i)<o(s_j)$.
The $S$ is the optimal sequence for ESP.

Recall the definition of $o_i$, we just sort all the edges according to the number of neighboring edges probed before the edge.
For short, we call ``the number of neighboring edges probed before the edge'' as the \textit{order} of the edge.
Now, we are going to demonstrate that $S^*$ is the optimal sequence.
The rough idea is that the optimal solution of ILP is always implementable by ESD.
The reason is that an edge always probed earlier than one with higher order.
Otherwise, let lower-order edge be probed first can increase the value of the objective function.

Formally, it is stated as follows.

\begin{theorem}
	The output sequence $S^*$ of our algorithm is the sequence that maximizes the cardinality in the ESD algorithm.
\end{theorem}

\begin{proof}
	The proof of this theorem consists of two parts. In the first part, we show that any sequence of edges corresponds to a point in the ILP's solution space. 
	Then, we show that the sequence constructed by the mapping process corresponds to the optimal solution of the ILP.
	
	First, given a sequence of edges $S=s_1,s_2,\ldots,s_m$, we can construct the variables in the ILP as follows.
	For any $i<j$ and $e_i$ and $e_j$ have a common edge. $delta_{ij}=1$, otherwise $\delta_{ij}=0$.
	Let $o_i$ equal to $\sum_{j=1}^{m}\delta_{ji}$.
	$l_j=1$ if and only if $o_i\geq j$.
	We call this process as \textit{reverse mapping}.
	In this way, we have map $S$ to a point in the solution space of the ILP.
	Further, the value of objective function under this construction is exactly the expected number of matched edges.
	So we conclude the maximum objective function value is greater than or equal to the maximum expected number of matched edges.
	
	Second, we are going to show that $S^*$ corresponds to the optimum solution of the ILP by reverse mapping. 
	We prove this by contradiction. 
	According to Lemma \ref{lmm}, in the optimal solution $l_ij$'s are decided by $o_i$'s in the same way as reverse mapping.
	Further, $o_i$'s are decided by $\delta_{ij}$'s.
	So, when $\delta_{ij}$'s are fixed in  the optimal solution, all the other variables are fixed.
	By reverse mapping, if $S^*$ corresponds to the same $\delta_{ij}$'s as the optimum solution, the other variables are also the same.
	Let the mapping from $s_i^*$'s to $e_i$'s to be $g$, such that $s_i^*=e_{g(i)}$.
	By contradiction, we assume that in the optimum solution, $\delta_{g(i)g(j)}$ has a different value compared to the $\delta_{g(i)g(j)}$ reverse-mapped from $S^*$. 
	
	
	
	
\end{proof}


\newpage
\bibliographystyle{named}
\bibliography{matching}

\end{document}


